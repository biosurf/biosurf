---
title: "Batch correction of CyTOF data"
author: "Christina Bligaard Pedersen"
date: "September 13, 2021"
output: 
  html_document:
    toc: true
    toc_float: true
    highlight: kate
    df_print: paged
---
<style type="text/css">

h1.title {
  color: #004d66;
}
h4.author {
  font-style: italic;
  font-size: 18px;
  color: #008cba;
}
h4.date {
  font-style: italic;
  font-size: 16px;
  color: #008cba;
}
h1 { /* Header 1 */
  color: #004d66;
  font-size: 28px;
}
h2 { /* Header 2 */
  color: #004d66;
  font-size: 22px;
}
h3 { /* Header 3 */
  color: #004d66;
  font-size: 16px;
}
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
</style>


<br>

This vignette will demonstrate the batch correction of a CyTOF set consisting of 128 samples in seven batches using cyCombine. It will also include a small discussion regarding the grid size during batch correction.


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  strip.white = T, comment = ""
)

knitr::opts_knit$set(root.dir = '/home/projects/dp_immunoth/people/s134891/cycombine/DFCI/Mike_process')

```


<br>
This is data from a study of CLL patients and healthy donors at the Dana-Farber Cancer Institute (DFCI). The protein expression was quantified using mass cytometry for 128 samples (20 healthy donors). The data was run in seven batches and used a panel measuring expression of 36 proteins.


<br>

# Pre-processing data

We start by loading some packages.

```{r libraries, results = 'hide', warning=FALSE, message=FALSE}
library(cyCombine)
library(tidyverse)

```


<br>

We are now ready to load the CyTOF data. We have set up a panel file in csv format, so the correct information is extractable from there. Let us have a look at the contents:

```{r loading data 1, warning=FALSE, message=FALSE}
# Directory with raw .fcs files
data_dir <- "Panel1_renamed"

# Panel and reading data
panel <- read_csv("panel1.csv")
panel

```

<br>

We then progress with reading the CyTOF dataset and converting it to a tibble format, which is easy to process. We use cofactor = 5 (default) in this case.


```{r loading data 2}
# Extracting the markers
markers <- panel %>%
  filter(Type != "none") %>%
  pull(Marker) %>%
  str_remove_all("[ _-]")

# Preparing the expression data
dfci <- prepare_data(data_dir = data_dir,
                     metadata = "metadata.csv",
                     filename_col = "FCS_name",
                     batch_ids = "Batch",
                     condition = "Set",
                     markers = markers,
                     derand = TRUE,
                     down_sample = FALSE)

```

<br>

# Checking for batch effects
Now, let us use a cyCombine function to check if there are any batch effects to correct for at all... cyCombine will run on data even with no real batch effects, and in those cases, the batch correction should have minimal effect. However, there is no reason to run the algorithm, if we have no batch effects in the data.

```{r detect batch effects}
# We use the quicker version of the function. It generates three types of plots that may be useful in surveying a dataset for batch effects. Here, we also downsample since all cells are typically not needed to see batch effects.
detect_batch_effect_express(dfci, downsample = 10000, out_dir = 'batch_effect_check')

```
<br>

In the printed output, we already get some pointers to potential problems with batch effects. But let us look at each of these plots for this dataset. First we have the EMD per marker-plot, which shows the mean Earth Mover's Distance for all pairwise batch-to-batch comparisons. The distribution of each marker is considered globally for each comparison. The error bars represent the standard deviation. In this dataset, we observe a relatively high mean EMD for XCL1, and further this marker has a large standard deviation. This indicates that there may be a batch effect to consider in this marker - perhaps it is significantly over- or under-stained in one or more batches compared to the rest? According to the text, batch 1 is the problem. 

![](images/cyCombine/emd_per_marker.png)

<br>

To figure out if that is really the case, we can look at the second generated plot. This is the distribution of each marker in each batch. Quantiles are shown as vertical bars. 

When looking at XCL1, we clearly observe the batch effect indicated before - batch 1 looks very different from the rest! Also, have a look at TBet. This marker had the second-highest mean EMD above - and here, the distributions for batches 6 and 7 look different than the rest.  

![](images/cyCombine/distributions_per_batch.png)

<br>

Now for the final plot - a multidimensional scaling (MDS) plot. This form of dimensionality reduction can be used to detect outlier batches (or samples) based on the median marker expression per *sample*. Each dot corresponds to a sample - and the colors represent batches. If there are no batch effects, the pattern would be random - and though it can be hard to judge, here we will notice how the red batch 1 samples almost exclusively appear in the top part of the plot.
In other words, it looks a bit like batch effects!

![](images/cyCombine/MDS_per_batch.png)

<br>

We could dwell more at this, and we could also use the full `detect_batch_effect()` function of cyCombine to look at this more carefully. However, for now we are convinced that batch effects exist and we will correct them with cyCombine.



<br>

# Batch correction

Time to perform the batch correction:

```{r batch correction, message=FALSE, warning=FALSE, error=FALSE, results='hide'}
# Run batch correction
corrected <- dfci %>%
  batch_correct(covar = "condition",
                xdim = 8,
                ydim = 8,
                norm_method = 'scale',
                markers = markers)

```

<br>

# Evaluating performance

We start with some quantitative measurements of the correction performance.

```{r emd and mad, fig.height=5, fig.width=10, message=FALSE, warning=FALSE, error=FALSE, results='hide'}
# Cluster corrected data - and time the operation
start_time_8 <- Sys.time()
labels <- corrected %>%
          cyCombine::create_som(rlen = 10,
                                xdim = 8,
                                ydim = 8,
                                markers = markers)
end_time_8 <- Sys.time()

# Add labels
corrected <- corrected %>%
  dplyr::mutate(som = labels)

# Set column for evaluation of EMD (per-cluster)
celltype_col <- "som"

# Transfer labels to uncorrected data
dfci <- corrected %>%
  dplyr::select(id, all_of(celltype_col)) %>%
  dplyr::left_join(dfci, by = "id")

# Evaluation using EMD
emd_val <- dfci %>%
      cyCombine::evaluate_emd(corrected,
                              binSize = 0.1,
                              markers = markers,
                              cell_col = celltype_col)

# Show plots
cowplot::plot_grid(emd_val$violin, emd_val$scatterplot)


# Evaluation using MAD
mad_val <- dfci %>%
      cyCombine::evaluate_mad(corrected,
                              filter_limit = NULL,
                              markers = markers,
                              cell_col = celltype_col)

```

```{r mad score print, echo=FALSE}
cat('The MAD score is:', mad_val$score, '\n')

```



Let us also look at some plots to visualize the correction. First, the marker distributions before and after:

```{r density plot, message=FALSE, fig.height=22, fig.width=12}
plot_density(dfci, corrected, ncol = 4)

```

<br>

Finally, some UMAPs to visualize the correction. We will downsample to 5,000 cells from each batch so it is easier to see what is going on.

```{r umaps, fig.height=8, fig.width=16}
inds <- split(1:length(dfci$batch), dfci$batch)
set.seed(6157)
sample <- unlist(lapply(inds, sample, 5000))

plot1 <- plot_dimred(dfci[sample,], name = 'Uncorrected', type = 'umap')
plot2 <- plot_dimred(corrected[sample,], name = 'Corrected 8x8', type = 'umap')

cowplot::plot_grid(plot1, plot2)

```


<br>

Based on the marker distributions after correction and the UMAPs, it looks like the batch effects are eliminated. We can now address our biological questions. However, we have simply used the default grid size of 8x8 in this example. The clustering with the self-organizing map is used to group similar cells, for which batch correction can be performed properly for a more homogeneous set of cells. While 64 clusters should be enough for most PBMC analyses, the default grid size may not always be appropriate. 


<br><br>

# Grid size discussion

Rare subsets can be missed when using smaller grids, depending on their specific expression pattern and how distinct the rare cell type is from the other cells in the data. This problem is not unique to cyCombime, but rather a function of the SOM itself (which also happens to be the foundation of the widely FlowSOM clustering approach). 

<br>

If greater heterogeneity is anticipated in a dataset, we recommend increasing the grid size. Generally, one should aim for a grid size which can capture the variance of the data, but it is not a goal in itself to strongly over-cluster as this will increase the risk of having clusters that do not contain cells from all of the batches, resulting in a worse correction (or only cells from a single batch, resulting in no correction at all). As in any analysis involving a clustering step, we would recommend initial explorations of all datasets to establish an idea of the heterogeneity in the data, and then set the grid size accordingly when running cyCombine.



<br>

One way to get an idea about the heterogeneity in a dataset could be to run a clustering tool which automatically determines the number of clusters (e.g. Phenograph) using all the markers and letting the number of clusters obtained be a guide. Otherwise one could use ConsensusClusterPlus (the meta-clustering engine of FlowSOM) with the elbow criterion as discussed [here](https://www.bioconductor.org/packages/release/workflows/vignettes/cytofWorkflow/inst/doc/cytofWorkflow.html#reducing-the-number-of-clusters-in-consensusclusterplus). However, because of the batch effects, it can be problematic to cluster across batches on the uncorrected dataset (the investigation of clusters should take place before applying cyCombine), as it can lead to over-estimation of the cluster count. In this example, we normalize the data using scaling (per-batch) before doing clustering (analogously to the cyCombine workflow). We will select a 10x10 grid for the initial clustering and then use ConsensusClusterPlus with up to 90 (maximum allowed) clusters.

```{r cluster and elbow, results = 'hide', warning=FALSE, message=FALSE}
# Scaling and clustering using a SOM
seed = 9735
som_ <- dfci %>% 
  cyCombine::normalize(markers = markers, norm_method = 'scale') %>% 
  dplyr::select(all_of(markers)) %>% as.matrix() %>% 
    kohonen::som(grid = kohonen::somgrid(xdim = 10, ydim = 10), 
      rlen = 10, dist.fcts = "euclidean")

# Extracting the SOM codes (the SOM grid placement for each of the 100 nodes)
codes <- som_$codes[[1]]

# Making a meta-clustering and plotting the delta area plot
library(ConsensusClusterPlus)
mc <- ConsensusClusterPlus(t(codes), maxK = 90, reps = 100,
                           pItem = 0.9, pFeature = 1, plot = 'png', title = 'batch_effect_check',
                           clusterAlg = "hc", innerLinkage = "average", finalLinkage = "average",
                           distance = "euclidean", seed = seed)

```

![](images/cyCombine/delta_plot.png)

<br> 

The delta area plot shows the relative change in cluster stability (area under CDF curve), when adding one extra meta-cluster. The goal is to choose a *k* where there is no significant increase. In this case, that occurs around *k* = 25 or *k* = 30 depending on how strict the requirement is. In any case, this shows that usign 64 SOM nodes should capture the total data variance for batch correction.

<br><br>

## Testing different grid sizes
One could also address the question of the optimal grid size by simply trying multiple sizes. We will demonstrate the results for 2x2, 4x4, 12x12, and 16x16 grids below. We will also time each correction:

```{r different grid sizes 1, message=FALSE, warning=FALSE, error=FALSE, results='hide'}
# Run batch correction with 2x2 grid
start_time_2 <- Sys.time()
corrected2 <- dfci %>%
  batch_correct(covar = "condition",
                xdim = 2,
                ydim = 2,
                norm_method = 'scale',
                markers = markers)
end_time_2 <- Sys.time()

# Run batch correction with 4x4 grid
start_time_4 <- Sys.time()
corrected4 <- dfci %>%
  batch_correct(covar = "condition",
                xdim = 4,
                ydim = 4,
                norm_method = 'scale',
                markers = markers)
end_time_4 <- Sys.time()

# Run batch correction with 12x12 grid
start_time_12 <- Sys.time()
corrected12 <- dfci %>%
  batch_correct(covar = "condition",
                xdim = 12,
                ydim = 12,
                norm_method = 'scale',
                markers = markers)
end_time_12 <- Sys.time()

# Run batch correction with 16x16 grid
start_time_16 <- Sys.time()
corrected16 <- dfci %>%
  batch_correct(covar = "condition",
                xdim = 16,
                ydim = 16,
                norm_method = 'scale',
                markers = markers)
end_time_16 <- Sys.time()

```

<br>

Now, we can evaluate the performance using the EMD reduction and MAD score.

```{r different grid sizes 2, fig.height=5, fig.width=10, message=FALSE, warning=FALSE, error=FALSE, results='hide'}
# Make a function for evaluation
evaluate <- function(uncorrected, corrected, gridsize, markers, celltype_col = 'som') {
  
  # Cluster corrected data (still using 8x8 so we can compare directly to the 8x8 grid correction)
  labels <- corrected %>%
            cyCombine::create_som(rlen = 10,
                                  xdim = 8,
                                  ydim = 8,
                                  markers = markers)
  # Add labels
  corrected <- corrected %>%
    dplyr::mutate(som = labels)
  uncorrected <- uncorrected %>%
    dplyr::mutate(som = labels)
  
  # Evaluation using EMD
  emd_val <- uncorrected %>%
        cyCombine::evaluate_emd(corrected,
                                binSize = 0.1,
                                markers = markers,
                                cell_col = celltype_col)
  
  # Evaluation using MAD
  mad_val <- uncorrected %>%
        cyCombine::evaluate_mad(corrected,
                                filter_limit = NULL,
                                markers = markers,
                                cell_col = celltype_col)

  # UMAP - 5,000 cells per batch
  inds <- split(1:length(uncorrected$batch), uncorrected$batch)
  set.seed(6157)
  sample <- unlist(lapply(inds, sample, 5000))
  
  plot1 <- plot_dimred(uncorrected[sample,], name = 'Uncorrected ', type = 'umap')
  plot2 <- plot_dimred(corrected[sample,], name = paste0('Corrected ', gridsize, 'x', gridsize), type = 'umap')
  
  # umaps <- cowplot::plot_grid(plot1, plot2)
  
  # # Density plots
  # densities <- plot_density(dfci, corrected2, ncol = 6, markers = markers,
  #                           dataset_names = c('Uncorrected', paste0('Corrected ', gridsize, 'x', gridsize)))

  
  return(list('emd_val' = emd_val, 'mad_val' = mad_val, 'umaps' = list(plot1, plot2)))#, 'densities' = densities))
}

# Use function to evaluate
eval2 <- evaluate(dfci, corrected2, gridsize = 2, markers)
eval4 <- evaluate(dfci, corrected4, gridsize = 4, markers)
eval12 <- evaluate(dfci, corrected12, gridsize = 12, markers)
eval16 <- evaluate(dfci, corrected16, gridsize = 16, markers)

```


```{r different grid sizes 3, echo=FALSE}
cat('For the 2x2 grid, the EMD reduction is:', eval2$emd_val$reduction, 'and the MAD score is:', eval2$mad_val$score, '\n')
cat('For the 4x4 grid, the EMD reduction is:', eval4$emd_val$reduction, 'and the MAD score is:', eval4$mad_val$score, '\n')
cat('For the 12x12 grid, the EMD reduction is:', eval12$emd_val$reduction, 'and the MAD score is:', eval12$mad_val$score, '\n')
cat('For the 16x16 grid, the EMD reduction is:', eval16$emd_val$reduction, 'and the MAD score is:', eval16$mad_val$score, '\n')

```

<br>

What we observe here, is that using the very small 2x2 grid, there is still a reduction in the batch effects for this dataset, but it is not as strong as for the other settings. For 4x4, the reduction is slightly worse than for the 8x8 grid, used in the study, and 12x12 actually appears to be slightly better, with an EMD reduction of 0.68 (vs. 0.66) and the same MAD score (0.02) as for the 8x8 grid. However, the differences for 8x8, 12x12, and 16x16 are very small.

<br>

We can also compare the runtimes of the different settings.

```{r different grid sizes 4, echo=FALSE}
cat('For the 2x2 grid, the runtime was:', round(end_time_2 - start_time_2, 2), 'minutes\n')
cat('For the 4x4 grid, the runtime was:', round(end_time_4 - start_time_4, 2), 'minutes\n')
cat('For the 8x8 grid, the runtime was:', round(end_time_8 - start_time_8, 2), 'minutes\n')
cat('For the 12x12 grid, the runtime was:', round(end_time_12 - start_time_12, 2), 'minutes\n')
cat('For the 16x16 grid, the runtime was:', round(end_time_16 - start_time_16, 2), 'minutes\n')

```


<!-- We can round off by looking at the density plots: -->

<!-- ```{r different grid sizes 6, message=FALSE, fig.height=16, fig.width=16} -->
<!-- eval2$densities -->
<!-- eval4$densities -->
<!-- eval12$densities -->
<!-- eval16$densities -->

<!-- ``` -->

<br>
The runtimes do however increase with larger grid sizes, and since there is no significant performance gain in increasing the grid size beyond 8x8, we have used this for the analyses in the cyCombine article. We can also conclude that when the dataset consists of a large number of cells, the grid size is not a highly important parameter. This allows the user not to worry too much about finding an optimal value.

<br>

We have included the UMAPs for the different settings below:

```{r different grid sizes 5, fig.height=10, fig.width=16}
# UMAP plots for the tested settings
cowplot::plot_grid(eval2$umaps[[1]], eval2$umaps[[2]], 
                   eval4$umaps[[2]], plot2,
                   eval12$umaps[[2]], eval16$umaps[[2]])

```


<!-- One example could be to cluster the dataset. Here, we will display the results of Phenograph clustering. Actually, I will compare Phenograph run for all seven batches *with* and *without* batch correction using the same set of markers. -->

<!-- <br> -->

<!-- ```{r phenograph, results = 'hide', warning=FALSE, message=FALSE} -->
<!-- # Define the markers to use for clustering -->
<!-- cl_markers <- c('CD3', 'CD45RA', 'CD14', 'CD45RO', 'CD152', 'CD33', 'CD4', 'CD8', 'CD197', 'CD56', 'FoxP3', 'CD25') -->

<!-- # Run Phenograph (slow step ~4.5 hours for each dataset) -->
<!-- pheno_uncor <- Rphenograph(data = dfci[,cl_markers]) -->
<!-- pheno_cor <- Rphenograph(data = corrected[,cl_markers]) -->
<!-- ``` -->

<!-- ```{r phenograph n_cl} -->
<!-- cat(paste0('According to Phenograph, there are ', length(unique(pheno_uncor[[2]]$membership)), ' clusters in the combined, uncorrected dataset.\n')) -->

<!-- cat(paste0('According to Phenograph, there are ', length(unique(pheno_cor[[2]]$membership)), ' clusters in the combined, batch corrected dataset.\n')) -->
<!-- ``` -->

<!-- The fact that fewer clusters are found after batch correction illustrates that we have a more well-combined dataset, in which the chance of having smaller batch-specific clusters is minimized. -->

<!-- Now, one would normally proceed to labeling these clusters and looking for differential abundance between experimental conditions and so on. We will leave it here for now. -->